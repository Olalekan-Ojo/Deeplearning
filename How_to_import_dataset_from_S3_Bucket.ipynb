{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLOL6VjUAzj6zaPCV+pTPW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olalekan-Ojo/Deeplearning/blob/main/How_to_import_dataset_from_S3_Bucket.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Install Libraries\n",
        "```\n",
        "Boto3 is a library for setting up and interating with Amazon Web Services (AWS) in your python code.\n",
        "\n",
        "tqdm is a library for displaying progress bars\n",
        "\n"
      ],
      "metadata": {
        "id": "h6_Nz5B9L6J6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP2OH9ZMLa7P"
      },
      "outputs": [],
      "source": [
        "!pip install boto3\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from pathlib import Path\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "DLKL6p9tLcp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-File and Folder names are retrived from s3 bucket using `list_object_v2` method from boto3 library initially imported.\n",
        "\n",
        "'bucket_name' is the name of the s3 bucket you want to retrieve data from\n",
        "\n",
        "-The loop is used to ilterate through the results of the `list_objects_v2` and check if it represents a file or a folder based on the presence of a trailing slash in the key\n",
        "\n",
        "-The process is repeated till all the files are checked\n",
        "\n"
      ],
      "metadata": {
        "id": "B0iWBsnPMsoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_folders(s3_client, bucket_name, prefix=\"\"):\n",
        "    file_names = []\n",
        "    folders = []\n",
        "\n",
        "    default_kwargs = {\n",
        "        \"Bucket\": bucket_name,\n",
        "        \"Prefix\": prefix\n",
        "    }\n",
        "    next_token = \"\"\n",
        "\n",
        "    while next_token is not None:\n",
        "        updated_kwargs = default_kwargs.copy()\n",
        "        if next_token != \"\":\n",
        "            updated_kwargs[\"ContinuationToken\"] = next_token\n",
        "\n",
        "        response = s3_client.list_objects_v2(**updated_kwargs)\n",
        "        contents = response.get(\"Contents\")\n",
        "\n",
        "        for result in contents:\n",
        "            key = result.get(\"Key\")\n",
        "            if key[-1] == \"/\":\n",
        "                folders.append(key)\n",
        "            else:\n",
        "                file_names.append(key)\n",
        "\n",
        "        next_token = response.get(\"NextContinuationToken\")\n",
        "\n",
        "    return file_names, folders"
      ],
      "metadata": {
        "id": "QwZ5z6GLLgPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `download_files` downloads files from the S3 bucket to a local directory"
      ],
      "metadata": {
        "id": "en127w9BRVnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_files(s3_client, bucket_name, local_path, file_names, folders):\n",
        "    local_path = Path(local_path)\n",
        "\n",
        "    for folder in tqdm(folders):\n",
        "        folder_path = Path.joinpath(local_path, folder)\n",
        "\t\t\t\t# Create all folders in the path\n",
        "        folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for file_name in tqdm(file_names):\n",
        "        file_path = Path.joinpath(local_path, file_name)\n",
        "\t\t\t\t# Create folder for parent directory\n",
        "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        s3_client.download_file(\n",
        "            bucket_name,\n",
        "            file_name,\n",
        "            str(file_path)\n",
        "        )"
      ],
      "metadata": {
        "id": "FOs9eBj9Lg-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the files are downloaded as a zipped file using the `get_file_folders` and `download_files` function\n",
        "\n",
        "The local directory for the downloaded dataset is also defined.\n",
        "\n",
        "*PLEASE NOTE*\n",
        "The name of the s3 bucket file should be inputted as shown in AWS\n",
        "\n"
      ],
      "metadata": {
        "id": "Lcj4AdMKSEza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "file_names, folders = get_file_folders(client, 'INSERT NAME OF THE DATASET')"
      ],
      "metadata": {
        "id": "63XAiI_JLkC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_files(\n",
        "        client,\n",
        "        'INSERT NAME OF THE DATASET',\n",
        "        \"LOCAL DIRECTORY TO DOWNLOAD DATASET\",\n",
        "        file_names,\n",
        "        folders\n",
        "    )"
      ],
      "metadata": {
        "id": "PXyprBJuLlXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping the Downlaoded dataset to explore the content"
      ],
      "metadata": {
        "id": "n73QGoPVTVGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# specify the path of the zip file\n",
        "zip_file_path = \"images.zip\"\n",
        "# create a ZipFile object\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # extract all files to the current directory\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "id": "eWXOHurZLn-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fqH9OmU6Lfuu"
      }
    }
  ]
}